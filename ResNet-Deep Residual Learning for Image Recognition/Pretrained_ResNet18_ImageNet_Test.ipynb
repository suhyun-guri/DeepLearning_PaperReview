{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5f5dbf9",
   "metadata": {},
   "source": [
    "- 코드 원본 : [ndb796 / Deep-Learning-Paper-Review-and-Practice](https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/Pretrained_ResNet18_ImageNet_Test.ipynb)\n",
    "### 사전 학습된 ResNet 사용해보기\n",
    "- 본 실습에서는 ResNet18 모델을 이용해 이미지 분류(classification) 실습을 진행합니다.\n",
    "  - PyTorch Hub 공식 ResNet18 아키텍처를 이용해 학습된 모델을 이용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b4fd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\myksh\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\myksh\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "# 필요한 PyTorch 라이브러리 불러오기\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4247dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 장치 사용 설정\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1add2c1",
   "metadata": {},
   "source": [
    "# ImageNet에 정의된 클래스 정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "194a5c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "\n",
    "# 이미지넷(ImageNet)에 정의된 1,000개의 레이블(클래스) 정보 가져오기\n",
    "imagenet_json, _ = urlretrieve('http://www.anishathalye.com/media/2017/07/25/imagenet.json')\n",
    "with open(imagenet_json) as f:\n",
    "    imagenet_labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38b839b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "magpie\n"
     ]
    }
   ],
   "source": [
    "# 인덱스(index) 18에 해당하는 클래스는 까치(magpie)입니다.\n",
    "print(imagenet_labels[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616ca45",
   "metadata": {},
   "source": [
    "## 이미지 처리 함수 정의 및 이미지 가져와 출력해보기\n",
    "- ResNet은 일반적으로 이미지에 대하여 Resize, CenterCrop, ToTensor()와 입력 데이터 정규화를 사용하는 모델입니다.\n",
    "- 기본적으로 이미지가 들어왔을 때 바로 사용하는 것이아니라 이미지 크기를 224,224로 전처리하여 torch 모델에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a100ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256), # 이미지의 크기를 변경\n",
    "    transforms.CenterCrop(224), # 이미지의 중앙 부분을 잘라서 크기 조절\n",
    "    transforms.ToTensor(), # torch.Tensor 형식으로 변경 [0, 255] → [0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db541709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지(그림) 출력 관련 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a967590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정한 경로에서 이미지를 가져와 torch.Tensor로 변환하는 함수\n",
    "def image_loader(path):\n",
    "    image = PIL.Image.open(path)\n",
    "    # 전처리 이후에 네트워크 입력에 들어갈 이미지에 배치 목적의 차원(dimension) 추가\n",
    "    image = preprocess(image).unsqueeze(0)\n",
    "    return image.to(device, torch.float) # GPU로 올리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "033cb4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제로 특정 URL에서 이미지를 불러오기 (얼룩 고양이)\n",
    "url = \"https://s3.ap-northeast-2.amazonaws.com/elasticbeanstalk-ap-northeast-2-176213403491/media/magazine_img/magazine_280/5-3-%EC%8D%B8%EB%84%A4%EC%9D%BC.jpg\"\n",
    "image_path, _ = urlretrieve(url)\n",
    "image = image_loader(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68742928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.Tensor 형태의 이미지를 화면에 출력하는 함수\n",
    "def imshow(tensor):\n",
    "    # matplotlib는 CPU 기반이므로 CPU로 옮기기\n",
    "    image = tensor.cpu().clone()\n",
    "    # torch.Tensor에서 사용되는 배치 목적의 차원(dimension) 제거\n",
    "    image = image.squeeze(0)\n",
    "    # PIL 객체로 변경 \n",
    "    image = transforms.ToPILImage()(image)\n",
    "    # 이미지를 화면에 출력(matplotlib는 [0, 1] 사이의 값이라고 해도 정상적으로 처리)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d3f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5586e981",
   "metadata": {},
   "source": [
    "# 사전 학습된(pretrained) 모델을 불러와 사용해보기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6405f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 정규화를 위한 클래스 정의\n",
    "class Normalize(nn.Module) :\n",
    "    def __init__(self, mean, std) :\n",
    "        super(Normalize, self).__init__()\n",
    "        self.register_buffer('mean', torch.Tensor(mean))\n",
    "        self.register_buffer('std', torch.Tensor(std))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        mean = self.mean.reshape(1, 3, 1, 1)\n",
    "        std = self.std.reshape(1, 3, 1, 1)\n",
    "        return (input - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53f959fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/v0.6.0.zip\" to C:\\Users\\myksh/.cache\\torch\\hub\\v0.6.0.zip\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\myksh/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a5ff07b97a469f8890603ae71aaa9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 공격자가 가지고 있는 torch.Tensor 형식의 이미지 데이터는 입력 정규화를 거치기 전이므로, 정규화 이후에 모델에 넣도록 설정\n",
    "model = nn.Sequential(\n",
    "    # 기본적인 ResNet18과 동일한 동작을 위하여 정규화 레이어 추가\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n",
    ").to(device).eval() # 모델을 GPU로 옮기기 및 평가(테스트) 모드로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd459b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< 가장 높은 확률을 가지는 클래스들 >\n",
      "인덱스: 282 / 클래스명: tiger cat / 확률: 52.1841%\n",
      "인덱스: 281 / 클래스명: tabby, tabby cat / 확률: 27.5889%\n",
      "인덱스: 285 / 클래스명: Egyptian cat / 확률: 15.4467%\n",
      "인덱스: 287 / 클래스명: lynx, catamount / 확률: 2.2962%\n",
      "인덱스: 673 / 클래스명: mouse, computer mouse / 확률: 0.3148%\n"
     ]
    }
   ],
   "source": [
    "# 기본적인 이미지를 실제 모델에 넣어 결과 확인\n",
    "outputs = model(image)\n",
    "# 확률을 계산하기 위해 소프트맥스(softmax) 함수 취하기\n",
    "percentages = torch.nn.functional.softmax(outputs, dim=1)[0] * 100\n",
    "# 가장 높은 값을 가지는 5개의 인덱스를 하나씩 확인하며\n",
    "print(\"< 가장 높은 확률을 가지는 클래스들 >\")\n",
    "for i in outputs[0].topk(5)[1]:\n",
    "    # 높은 값을 가지는 순서대로 인덱스에 해당하는 클래스 이름과, 그 확률 값 출력하기\n",
    "    print(f\"인덱스: {i.item()} / 클래스명: {imagenet_labels[i]} / 확률: {round(percentages[i].item(), 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a312b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17515ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fb99c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
